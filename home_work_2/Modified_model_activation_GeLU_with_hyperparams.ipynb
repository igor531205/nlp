{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igor531205/nlp/blob/main/home_work_2/Modified_model_activation_GeLU_with_hyperparams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Выполнил Пушкарев Игорь Игоревич. Группа 23.М08-мм.***"
      ],
      "metadata": {
        "id": "nVmyYXdnD98g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformers."
      ],
      "metadata": {
        "id": "T5wYnQ3Y_pYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Modified model, activation function GeLU, (18 layers, dff = 2048, H = 8)*"
      ],
      "metadata": {
        "id": "eNCI37vw8yFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 256 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_dff = 2048 # add the hyperparameter dff\n",
        "n_head = 8 # replacing the hyperparameter H 6\n",
        "n_layer = 18 # replacing the hyperparameter layers 6\n",
        "dropout = 0.2\n",
        "\n",
        "torch.manual_seed(1337);\n",
        "\n",
        "# with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "#     text = f.read()\n",
        "\n",
        "from urllib import request\n",
        "\n",
        "# read in all the words\n",
        "link = 'https://raw.githubusercontent.com/igor531205/nlp/main/data/input.txt'\n",
        "with request.urlopen(link) as f:\n",
        "    text = f.read().decode()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input of size (batch, time-step, channels)\n",
        "        # output of size (batch, time-step, head size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_dff):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, n_dff),\n",
        "            nn.GELU(), # replacing the activation function ReLU()\n",
        "            nn.Linear(n_dff, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd, n_dff)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "perplexity_log = f'perplexity_train,perplexity_val\\n'\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        if iter == max_iters - 1:\n",
        "            perplexity_log += f\"{torch.exp(losses['train']):.4f},{torch.exp(losses['val']):.4f}\"\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "with open(\"perplexity_mod.txt\", \"w\") as file:\n",
        "    file.write(perplexity_log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89Ry5JzDIqVd",
        "outputId": "dd8063a6-03dc-4922-abe9-78ca8c620ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39.170388 M parameters\n",
            "step 0: train loss 4.4353, val loss 4.4263\n",
            "step 500: train loss 2.4683, val loss 2.5064\n",
            "step 1000: train loss 1.9144, val loss 2.0885\n",
            "step 1500: train loss 1.5301, val loss 1.9105\n",
            "step 2000: train loss 1.2087, val loss 1.9558\n",
            "step 2500: train loss 0.8098, val loss 2.2409\n",
            "step 3000: train loss 0.4246, val loss 2.7162\n",
            "step 3500: train loss 0.1992, val loss 3.3254\n",
            "step 4000: train loss 0.1213, val loss 3.7284\n",
            "step 4500: train loss 0.0986, val loss 4.0162\n",
            "step 4999: train loss 0.0904, val loss 4.2667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# print perplexity\n",
        "df=pd.read_csv(\"perplexity_mod.txt\", index_col=False)\n",
        "df"
      ],
      "metadata": {
        "id": "lR_dAzvdNcfL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "a55bbd74-6db1-43dd-f6ca-1ec77e14d3df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   perplexity_train  perplexity_val\n",
              "0            1.0946         71.2825"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2262393d-1004-468c-a9f0-e9bd476276c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>perplexity_train</th>\n",
              "      <th>perplexity_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0946</td>\n",
              "      <td>71.2825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2262393d-1004-468c-a9f0-e9bd476276c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2262393d-1004-468c-a9f0-e9bd476276c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2262393d-1004-468c-a9f0-e9bd476276c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"perplexity_train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0946,\n        \"max\": 1.0946,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0946\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perplexity_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 71.2825,\n        \"max\": 71.2825,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          71.2825\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "with open(\"more_mod.txt\", \"w\") as file:\n",
        "    file.write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))\n",
        "\n",
        "with open('more_mod.txt', 'r', encoding='utf-8') as f:\n",
        "    more = f.read()\n",
        "\n",
        "print(more)"
      ],
      "metadata": {
        "id": "ljgHfmRlkehV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ba25b9-4848-4cec-ca82-5e28bc29f520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Волненик ужас на лоне лиши, \n",
            "Игривых струн волн онем чит под сводом \n",
            "Владыки радости царя - уж белезный старик, \n",
            "Расправя крылья горделивы, \n",
            "К краский рад теперь сохранил \n",
            "Струею встречала страшно стогой \n",
            "е покоенной бородец, \n",
            "С конюшным ополченкой, \n",
            "Битающий за кровавой науке \n",
            "Он напосланный — увядшей в лицо! \n",
            "И тихо божества и тени \n",
            "Входит за рубольей не стучал. \n",
            "Ее бедный твой опот в крови.ая \n",
            "Страшись весель, обвидить милый м, \n",
            "Места, где я грусть и страх \n",
            "Оживленный маком обидал \n",
            "И никогда не во собак \n",
            "Силог сладкий некогда Монах \n",
            "Свои послушливый наслаждений, \n",
            "Отвергий им нраворных судей, \n",
            "В тебе забытый отдноком, тебе пущи волне, \n",
            "Воспетых и стих, печатленный богатыря, \n",
            "На лире б и печальный простой, \n",
            "Я был дней на встречал суеты \n",
            "В одной сердца голубина, \n",
            "В благорковом слетельного счастья \n",
            "От малых проз грозя и земной \n",
            "\n",
            "От скрыткнул его внимала, \n",
            "И я в пустынной черной \n",
            "Сквозь нежный мла бедный круг соль, \n",
            "Вспоминательную душой \n",
            "И подарит невольный и полна, \n",
            "Она внемлет уж носилась \n",
            "На мрамор гордой на солнце \n",
            "Кто скрыт, по небо взывает \n",
            "Там в шалХе и мертвопой \n",
            "Кинулы предательный позор!. \n",
            "\n",
            "Любом зрит стучителя народ \n",
            "И подсвеленный порок \n",
            "Любви лип — леса, не страданья \n",
            "Под сенью прада дремлющим забами \n",
            "Не беззнадется один за ночем. \n",
            "\n",
            "Он русской владой непоги исновал \n",
            "И видя в животе всей дух милой, \n",
            "Занерамый издох клеветы в \n",
            "Джал парусских и обедов \n",
            "Кто, видно, увидить он в \n",
            "Духу не прозрачнет бедный \n",
            "Расскаяться бедный Царь \n",
            "Над сельской берег спит, \n",
            "арисмах державно лица, \n",
            "Притекла хватского собраня, \n",
            "Но в кистатерике разжить \n",
            "Герой поропись его тревогой. \n",
            "И вольностью моей пустынной грустой, \n",
            "Мой тих, увы, мой милый друг, \n",
            "Куда же снова перед нами свободы, \n",
            "Где в нас жало девы мир час есть \n",
            "Затором громы видом науку \n",
            "Звенит праведный снова раз \n",
            "Смиренным наших бурь,  но вечно возлющий \n",
            "Словами истины, свободы кони. \n",
            "Лихие в Боювы следые \n",
            "Подрелые сада, \n",
            "Теперь и Вакхом на прихота, \n",
            "Много внукал свое длани, \n",
            "О, боже, мне и ., но сколько слез \n",
            "И хочет нет от альбом мне. \n",
            "\n",
            "О вы, как в заабытые \n",
            "Ни сто, где чистые моей, \n",
            "Где я нежно давно приветы, \n",
            "Забытый мной слабый гений \n",
            "Не смел я вас бесплодной свидет\n",
            "Веселья шумное безды \n",
            "Во мраке ночи степь предрак от глубовый, \n",
            "И в мраке толчалися безумной\n",
            "Приближалась в тишине под шелом, \n",
            "В Юбку коротке вельмок добра Галафры, \n",
            "К могу дремучий из шагаетают, \n",
            "О кружаясь мы в кругом назумныма \n",
            "С тросниматься до утратя \n",
            "И победы самой черной \n",
            "И не ряд головы и настава, \n",
            "О, ты, который Слог на  советата \n",
            "Однако не разделает \n",
            "В убье счастливый гонитель \n",
            "Любимый Аполлон! \n",
            "Поэ-рамий ! вскупай! \n",
            "Говорить, пыл весь наша, \n",
            "Поди, теперь же помра: \n",
            "Во праву дорога. \n",
            "Боле поле унали, \n",
            "В военный и про стола \n",
            "Сыне в радости света \n",
            "И траву жизни скорца. \n",
            "\n",
            "Он говорит: \"Вчера трапезь \n",
            "Разнор вешних очей свет! \n",
            "Погаслась в увеселитель, \n",
            "О горе склонился смерть \n",
            "В уединели пешкрась \n",
            "Где горе и сердце поцелуй. \n",
            "Впервые сына беспечны \n",
            "От грозного сеял, взирая, \n",
            "Невесна — полно я друга \n",
            "В чистом пред себя пою \n",
            "Тихим изредка младого \n",
            "Остепенимным золотом. \n",
            "Полно, нет страшно певца, \n",
            "Обойородицы и Аполлона, \n",
            "Друга кругом и засныЗывала \n",
            "И в жизни сердце умолчала. \n",
            "Красавица вздохнула, — остолпал \n",
            "И грубокли снег, пона полна, \n",
            "Загляди на не лира одиного \n",
            "Любовь на всегда теперь со мной: \n",
            "Застыв безмолвный позор \n",
            "На вечной ли, милый нрав, бой врами \n",
            "На обратила на груды своей, \n",
            "Покое буря за тмира \n",
            "Стыдливый месяц полками, \n",
            "Откладев озарясь - с шахом. \n",
            "По крепкутам победным дружьями \n",
            "По волчанному окружали\n",
            "Наклонилса, и сам проказы, \n",
            "Прыгнули гений свершины \n",
            "Тоскар в глухой небес, \n",
            "В боях волос, в душе поварил \n",
            "Там воял: сетя Бог!\n",
            "\n",
            "По краше грудь и победе\n",
            "И пишь  — и пьеть кругом дремалет\n",
            "Одна гордую, обидим! Красоту мало!\n",
            "Беспытно вновь — Вельмож, и нет!\n",
            "Уж с редой гордости безгласной и Росси\n",
            "Скрывался в тень развивался сыбл.\n",
            "\n",
            "Стал на сим семьного сталася нежной,\n",
            "И плаще и с бирской склониливой\n",
            "И леглея твой станик силой,\n",
            "И селенью рифмой роковой,\n",
            "У меня обрать стал давно,\n",
            "Как в окровавленный мы забавой\n",
            "Редем торчает фораций,\n",
            "\n",
            "Слышь только будит гордый,\n",
            "Колых столат загороде\n",
            "Ахила гриву величавый.\n",
            "\n",
            "Жестокой судьба у забавы\n",
            "И в гробах круть! - может быстрый Слада\n",
            "Опять бы отпроватила:\n",
            "И вдруг бокала велица.\n",
            "Он слыша круговые, за ворот\n",
            "Счастливый друг китая страшит!\n",
            "\n",
            "Стократ вечная хладея,\n",
            "В безмолвии богачей\n",
            "Разбранной лести Тальи,\n",
            "Забыв неслистый труда,\n",
            "Ни родные тигри, холмы, \n",
            "Шепчет на берега мгустретам\n",
            "Свою люби, алею прекрасной,\n",
            "Я сражу от забываться\n",
            "Удивлять всех объятия трудов!\n",
            "\n",
            "Лишь только буду я не принесется\n",
            "С покой безмолвный Аполлон!\n",
            "Под сенью хладную досугой,\n",
            "Осеней правного Петра,\n",
            "Ее потемной наградил, зоилотой,\n",
            "Покров лежит под небесам хотело,\n",
            "Не опасен кровавый Эллины,\n",
            "Уставя безмолвную твореньший сени,\n",
            "И се шепот речь, и пламенные ночи,\n",
            "И междой сладостной минуты скал\n",
            "Над кровной пенистою могилой\n",
            "Свои страсти рощею луна.\n",
            "\n",
            "Все шалости с домеждой я кровавой\n",
            "Я домой перует, как молодой\n",
            "И за чашей виноют угрозой\n",
            "Мой навек от пылкий стол,\n",
            "Но сердце могучен поминает,\n",
            "Соблазнитель страх и крылья.\n",
            "\n",
            "Старик и свою грехововой,\n",
            "Свистя в угере с Столпа не смучит.\n",
            "\n",
            "Твое позело — Волгорит, народа\n",
            "Мольбе и не по-то был и ни туст,\n",
            "То их, ночь помогильно придеть.\n",
            "\n",
            "Стал бы я средь бога был дорожит,\n",
            "В бояромерном упоенье\n",
            "Ты предался бедным суомком\n",
            "В блеска, молчат, кажите, друзья,\n",
            "Ты говорил: \"не ль быть может отрада:\n",
            "\"Прости, будь ему приморского лет,\n",
            "Все моей пленит огонена,\n",
            "Воспоминаньем предай любви.\n",
            "\n",
            "И вы, которога народа…\n",
            "О руже оставилась с боязаки\n",
            "С тые вы, мой жребий в укоре леса,\n",
            "Чтоб старый волный поитель взор.\n",
            "Воспев, гордитель не по не смею,\n",
            "Хоть дал изгнаньем уопасть. —\n",
            "Но вот он в горе плечать он\n",
            "Делит с черкесского бредни\n",
            "Одушевляет на умеет.\n",
            "Теперь и одна собмкнет, \n",
            "И, принак богатый шампов\n",
            "И певец перопом доезжать,\n",
            "И греть он на утлом чашей,\n",
            "Решеной песни вешни образец,\n",
            "В архивый сын побед лет.\n",
            "Захочет промчат старик от бледнеет\n",
            "Бранись от лицем брадатья.\n",
            "Ведь убедный запол судьбины судьбины,\n",
            "Встречать веселый стократ и тени,\n",
            "В странствиях дум суерденых молина,\n",
            "На лоне мирт ли веерный зыбей,\n",
            "Коль мог вы, миром и любовь.\n",
            "\n",
            "Близь придет он сети своей молодой\n",
            "Беседую цепь он возрастит она,\n",
            "И векруг его всем чувствует ум.\n",
            "\n",
            "Дубравы нашей обнял холмы,\n",
            "Ни повалили времена.\n",
            "\n",
            "А те дни мне пришлось, унылый,\n",
            "И бледный теплится ночник\n",
            "На лога нам шертой тощит\n",
            "И твоего цевницы\n",
            "\n",
            "Ни вощей зеркой стал\n",
            "\n",
            "То верной мгле неистый,\n",
            "Оставь круг безысклонной,\n",
            "Переперьясь смятенья,\n",
            "В сенаты резвой холод\n",
            "Позднову лазаки придет\n",
            "Одна пришет образец.\n",
            "\n",
            "Но слушай — нет ли ты ступай хотелРа\n",
            "Чуть самлюбивых Аиссела».\n",
            "Видно б нам расстазил ли ты стане\".\n",
            "\n",
            "Возможно ль всё — сконя раздал\n",
            "И тихо всех кокошечко:\n",
            "Жено боброх скорета,\n",
            "Вся сам Фоева бывался,\n",
            "И с прелести тихо веет\n",
            "В \"Амур — \"Спарнасской —\n",
            "Вмиг исчезло парнасской,\n",
            "Народ, Не, надень расскошливо,\n",
            "Подщипа  семья умер.\n",
            "\n",
            "   Кормак несчастный фрак носит\n",
            "Я тихо забыл будет свет,\n",
            "А молит и поэт и сладость,\n",
            "Когда мы вновь — всюду свистом,\n",
            "Всё тео он бог он поет\n",
            "Всё спокойно в часо стал.\n",
            "Хотя молодицы, дух\n",
            "Сверкая посещаю\n",
            "С новою моим замечает.\n",
            "\n",
            "Возможно ль вас не родит\n",
            "На снежную грудь.\n",
            "Тюльзя за мною, мой наполники счастливой,\n",
            "Раскошный господин чернеец холодный,\n",
            "Подруги кровавый прах перстами свершил.\n",
            "Старик бессмертный и набожный гений\n",
            "И снег еее полюбить ныне забавешь,\n",
            "И разрешите торгов захохоту слову.\n",
            "\n",
            "И сколько чудный междую посох собедушенье:\n",
            "Они присятные, и ветреные морозы,\n",
            "Овины смехи надежд и трудов.\n",
            "Смертный парус рыбар не возвышен,\n",
            "Рукою черни беду я не видал\n",
            "Столь зающенным Парнасского влечет\n",
            "В пуглинах лесов, в пустыне молчаливой,\n",
            "Рюмок роще и пенистый стон поток малов\n",
            "В скрепите себя средь волною волной,\n",
            "Твоею скромной слетает ночи молодой.\n",
            "\n",
            "Приди, Одульфан жил на домой!\n",
            "Сын потер я томимель молодой.\n",
            "С ты, потупил в городких стучаках,\n",
            "Который порядок же мой гений,\n",
            "Не смел одцепия умею,\n",
            "Мечтанье — а смерть смертную,\n",
            "Одна срок волшебный совершил\n",
            "Забыв на своем благодарье:\n",
            "Люби недели тебя скупона:\n",
            "Беседы верилы самода,\n",
            "И сталы, и лжица полетал\n",
            "И сама на дружеским хозяйками\n",
            "Ела прозе — и нас родном дароми.\n",
            "\n",
            "Ведь каждый смерти над буками\n",
            "В ней страшности стеклом летет\n",
            "Одни строил нагой возбужденье\n",
            "Рассеял с свою судьбой!\n",
            "\n",
            "Дружбы серде обры сердечный,\n",
            "жад блистает лишь его,\n",
            "Да запертные забавы\n",
            "И темный обнимает народный.\n",
            "\n",
            "   Пробольте, храни моей!\n",
            "Умолкни, рассейска наслажденье:\n",
            "Соседи шубы по манию дайтей!\n",
            "\n",
            "Нет, нет! ни слезы наших дней!\n",
            "Увижу к нас желловиться безумной!\n",
            "Пришлец, когда же вознадеждать\n",
            "Равно последний раз незалых девым,\n",
            "О брат любовницу нам\n",
            "Не увлечен, вмы и прах замысловатым,\n",
            "Порошайте, пищины нам\n",
            "Об дорогой Натальянской молодых,\n",
            "Стекает он не строгих сильных страх,\n",
            "От Троско найде, на строевожит волны\n",
            "Ну лопну обещанных струн ополчалив:\n",
            "Но вдруг, как бегут тройка т, бесистальный,\n",
            "Качая головая и жизнь моя.\n",
            "Конюший ток беспечный гол свидетель,\n",
            "Я пил дерзостию взор незабвенный\n",
            "Остались глас во тьме ум ною:\n",
            "И наперсник — озарял. Мне страшный!…\n",
            "Увы! напом скрылись тебя венком,\n",
            "О знаешь: он в сердцем уме,\n",
            "Без легком зеркалось не полезал\n",
            "И торь бы новую лень снова\n",
            "\n",
            "\n",
            "Но бессмысленных творенье\n",
            "Я всему любил, чтобы слезы\n",
            "Ужели мне робко ленивые\n",
            "Заправ издали грозы свиток,\n",
            "И властитель рассы стороны\n",
            "Свои страстью в объятиях устачу,\n",
            "Здесь от Эвханов — и жар во мгле\n",
            "Его в блесках земли красавицы\n",
            "Увидел он бесчувственной круглы\n",
            "Храните гордости и слезы.\n",
            "\n",
            "   Плещут вольной сказатью стремнины,\n",
            "В кругу бесчувственной судьбы,\n",
            "Храни меня, мой талисман.\n",
            "\n",
            "Меж тем как пестрая семена,\n",
            "Но встретясь для разбором горе\n",
            "В указал на темный ряд\n",
            "Не раз клику склонялся монах.\n",
            "\n",
            "Шевей ты порой кругу свой незабвенный\n",
            "Стою песнь одой со мной, о ты, остротанный,\n",
            "С жаром волшебницы милой!\n",
            "О, ты затесь, хотя семянный певец,\n",
            "Богиня слабагаез предан тобой,\n",
            "По ней мгла новоселью беспечных.\n",
            "\n",
            "Неведозмутерный дух,\n",
            "Но страсти горестный!\n",
            "Измены, вечный забавы:\n",
            "Ты славил этот лампады\n",
            "И в груди мой послушный,\n",
            "Твой часто сонный лени\n",
            "Забвение налошенья\n",
            "Потонс твой танстов!\n",
            "Страшно станет стороный\n",
            "Мозаил и красой\n",
            "Урочительные черты.\n",
            "Смирись, так волны сад,\n",
            "Три страшный глас \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0nGzSd3C56Tk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}