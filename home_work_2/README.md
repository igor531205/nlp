# Model GPT based on a Transformer.
gpt.py - modified model with Evolved Transformer, activation function GeLU and hyperparameters (18 layers, dff = 2048, H = 8).

![Perplexity](perplexity.png)
